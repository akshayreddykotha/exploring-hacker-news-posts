{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HackerNews Posts Analysis\n",
    "Data from https://news.ycombinator.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis is based on importing some python modules without diving into more easy to use libraries like pandas, numpy. It is more of a next level than the previous project where python was hard coded by using the default functions, methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Goals**:\n",
    "1. Determine if show or ask posts receive more comments\n",
    "2. Which hours are more likely to receive more comments?\n",
    "3. Determine if show or ask posts receive more points\n",
    "4. Which hours are more likely to receive more points?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import and remove header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "f = open(\"hacker_news.csv\")\n",
    "readfile = csv.reader(f)\n",
    "\n",
    "hn = list(readfile)\n",
    "\n",
    "#First five rows of the dataframe created (list of lists)\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "headers\n",
    "\n",
    "#overwriting the hn list, hence I have to use [0:5] to display the first five rows of the new hn\n",
    "hn = hn[1:] \n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extraction ask HN, show HN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of posts with ask hn: 1744\n",
      "number of posts with show hn: 1162\n",
      "number of other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "#startswith for string check\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for each in hn:\n",
    "    title = each[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(each)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(each)\n",
    "    else:\n",
    "        other_posts.append(each)\n",
    "\n",
    "print(\"number of posts with ask hn:\",len(ask_posts))        \n",
    "\n",
    "print(\"number of posts with show hn:\",len(show_posts))\n",
    "\n",
    "print(\"number of other posts:\",len(other_posts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10627194',\n",
       "  'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform',\n",
       "  'https://iot.seeed.cc',\n",
       "  '26',\n",
       "  '22',\n",
       "  'kfihihc',\n",
       "  '11/25/2015 14:03'],\n",
       " ['10646440',\n",
       "  'Show HN: Something pointless I made',\n",
       "  'http://dn.ht/picklecat/',\n",
       "  '747',\n",
       "  '102',\n",
       "  'dhotson',\n",
       "  '11/29/2015 22:46'],\n",
       " ['11590768',\n",
       "  'Show HN: Shanhu.io, a programming playground powered by e8vm',\n",
       "  'https://shanhu.io',\n",
       "  '1',\n",
       "  '1',\n",
       "  'h8liu',\n",
       "  '4/28/2016 18:05'],\n",
       " ['12178806',\n",
       "  'Show HN: Webscope  Easy way for web developers to communicate with Clients',\n",
       "  'http://webscopeapp.com',\n",
       "  '3',\n",
       "  '3',\n",
       "  'fastbrick',\n",
       "  '7/28/2016 7:11']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_posts[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculating average number of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n",
      "Number of average comments for a show post is less than that of an ask post\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "#avg_ask_comments = 0\n",
    "\n",
    "#type conversion is mandatory check before any calculations. If it is integet by int, if it is string by str\n",
    "for each in ask_posts:\n",
    "    acomments = int(each[4])\n",
    "    total_ask_comments =  total_ask_comments + acomments\n",
    "    \n",
    "avg_ask_comments = (total_ask_comments/len(ask_posts))\n",
    "print(avg_ask_comments)\n",
    "                                                   \n",
    "for each in show_posts:\n",
    "    scomments = int(each[4])\n",
    "    total_show_comments =  total_show_comments + scomments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(avg_show_comments)\n",
    "\n",
    "if avg_show_comments > avg_ask_comments:\n",
    "    print(\"Number of average comments for a show post is greater than that of an ask post\")\n",
    "else:\n",
    "    print(\"Number of average comments for a show post is less than that of an ask post\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding:** Number of average comments for an ask post is greater than that of a show post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ask posts comments analysis - by hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two element list from ask_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8/16/2016 9:55', 6],\n",
       " ['11/22/2015 13:43', 29],\n",
       " ['5/2/2016 10:14', 1],\n",
       " ['8/2/2016 14:20', 3]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list =[]\n",
    "\n",
    "for each in ask_posts:\n",
    "    sublist = []\n",
    "    createdtime = each[6]\n",
    "    comments = int(each[4])\n",
    "    sublist.append(createdtime)\n",
    "    sublist.append(comments)\n",
    "    result_list.append(sublist)\n",
    "       \n",
    "result_list[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step helps us focus on the elements required to get the frequency table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency table creation using the sublist (date, comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': 641, '21': 1745, '03': 421, '22': 479, '18': 1439, '09': 251, '12': 687, '08': 492, '05': 464, '16': 1814, '02': 1381, '17': 1146, '15': 4477, '23': 543, '20': 1722, '06': 397, '07': 267, '04': 337, '14': 1416, '19': 1188, '13': 1253, '01': 683, '00': 447, '10': 793}\n",
      "{'11': 58, '21': 109, '03': 54, '22': 71, '18': 109, '09': 45, '12': 73, '08': 48, '05': 46, '16': 108, '02': 58, '17': 100, '15': 116, '23': 68, '20': 80, '06': 44, '07': 34, '04': 47, '14': 107, '19': 110, '13': 85, '01': 60, '00': 55, '10': 59}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for each in result_list:\n",
    "    dtobj = each[0]\n",
    "    dtparsed = dt.datetime.strptime(dtobj, \"%m/%d/%Y %H:%M\")\n",
    "    hr = dt.datetime.strftime(dtparsed,\"%H\")\n",
    "    #print(hr)\n",
    "    \n",
    "    if hr not in counts_by_hour:\n",
    "        counts_by_hour[hr] = 1\n",
    "        comments_by_hour[hr] = int(each[1])\n",
    "    else:\n",
    "        counts_by_hour[hr] = counts_by_hour[hr] + 1\n",
    "        comments_by_hour[hr] = comments_by_hour[hr] + int(each[1])\n",
    "\n",
    "print(comments_by_hour)\n",
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Average number of comments in an hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11', 11.051724137931034],\n",
       " ['21', 16.009174311926607],\n",
       " ['03', 7.796296296296297],\n",
       " ['22', 6.746478873239437],\n",
       " ['18', 13.20183486238532],\n",
       " ['09', 5.5777777777777775],\n",
       " ['12', 9.41095890410959],\n",
       " ['08', 10.25],\n",
       " ['05', 10.08695652173913],\n",
       " ['16', 16.796296296296298],\n",
       " ['02', 23.810344827586206],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['23', 7.985294117647059],\n",
       " ['20', 21.525],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['04', 7.170212765957447],\n",
       " ['14', 13.233644859813085],\n",
       " ['19', 10.8],\n",
       " ['13', 14.741176470588234],\n",
       " ['01', 11.383333333333333],\n",
       " ['00', 8.127272727272727],\n",
       " ['10', 13.440677966101696]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour,comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour    \n",
    "#1. lists can also be created from dictionaries\n",
    "#2. Calculatons can be done on the key values of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Sorting the final list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swapping the sublist elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.051724137931034, '11'], [16.009174311926607, '21'], [7.796296296296297, '03'], [6.746478873239437, '22'], [13.20183486238532, '18'], [5.5777777777777775, '09'], [9.41095890410959, '12'], [10.25, '08'], [10.08695652173913, '05'], [16.796296296296298, '16'], [23.810344827586206, '02'], [11.46, '17'], [38.5948275862069, '15'], [7.985294117647059, '23'], [21.525, '20'], [9.022727272727273, '06'], [7.852941176470588, '07'], [7.170212765957447, '04'], [13.233644859813085, '14'], [10.8, '19'], [14.741176470588234, '13'], [11.383333333333333, '01'], [8.127272727272727, '00'], [13.440677966101696, '10']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for each in avg_by_hour:\n",
    "    #print(key)\n",
    "    #creating a sublist and appending it\n",
    "    sublist = []\n",
    "    sublist.append(each[1])\n",
    "    sublist.append(each[0])\n",
    "    swap_avg_by_hour.append(sublist)\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 hours for ask posts comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask Posts Comments\n",
      "\n",
      "    15:00: 38.59 average comments per post    \n",
      "    \n",
      "\n",
      "    02:00: 23.81 average comments per post    \n",
      "    \n",
      "\n",
      "    20:00: 21.52 average comments per post    \n",
      "    \n",
      "\n",
      "    16:00: 16.80 average comments per post    \n",
      "    \n",
      "\n",
      "    21:00: 16.01 average comments per post    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#sorted function to arrange \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(\"Top 5 hours for Ask Posts Comments\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    hrobj = dt.datetime.strptime(sorted_swap[i][1],\"%H\") # Assigns what is what\n",
    "    hrobj_string = dt.datetime.strftime(hrobj, \"%H:%M\") #To final string\n",
    "    avg = sorted_swap[i][0]\n",
    "    template = '''\n",
    "    {}: {:.2f} average comments per post    \n",
    "    '''\n",
    "    print(template.format(hrobj_string,avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding**:\n",
    "\n",
    "The above times are in EST(eastern standard time). To get more comments, I (in IST) have to create a good number of posts during **01:30 - 02:30, 12:30 - 13:30, 06:30 - 07:30, 02:30 - 03:30, 07:30 - 08:30** in the same order. Basically, these are the early morning hours for an Indian resident with one exception of getting comments during the afternoo (in India).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### *Average number of points received by Ask and Show posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of points received by all ask post: 26268 \n",
      "Avg. number of points per ask post: 15.061926605504587 \n",
      "\n",
      "Total Number of points received by all show post: 32019 \n",
      " Avg. number of points per show post: 27.555077452667813 \n",
      "\n",
      "Number of points received on average by a show post is greater than that of an ask post\n"
     ]
    }
   ],
   "source": [
    "#ask_posts[0:5]\n",
    "apoints = 0\n",
    "spoints = 0\n",
    "\n",
    "for each in ask_posts:\n",
    "    apoints = apoints + int(each[3])\n",
    "\n",
    "print(\"Total Number of points received by all ask post:\", apoints, \"\\n\"\n",
    "      \"Avg. number of points per ask post:\", (apoints/len(ask_posts)),\"\\n\")\n",
    "\n",
    "for each in show_posts:\n",
    "    spoints = spoints + int(each[3])\n",
    "\n",
    "print(\"Total Number of points received by all show post:\", spoints,\"\\n\",\n",
    "      \"Avg. number of points per show post:\", (spoints/len(show_posts)),\"\\n\")\n",
    "\n",
    "if (apoints/len(ask_posts)) > (spoints/len(show_posts)):\n",
    "    print(\"Number of points received on average by an ask post is greater than that of a show post\")\n",
    "else:\n",
    "    print(\"Number of points received on average by a show post is greater than that of an ask post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding:** Number of points received on average by a show post is greater than that of an ask post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Finding out if show at certain times receive more points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As avg. number of points per show post is greater, we will continue further analysis on which times are likely to receive more point w.r.t show posts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10627194',\n",
       "  'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform',\n",
       "  'https://iot.seeed.cc',\n",
       "  '26',\n",
       "  '22',\n",
       "  'kfihihc',\n",
       "  '11/25/2015 14:03'],\n",
       " ['10646440',\n",
       "  'Show HN: Something pointless I made',\n",
       "  'http://dn.ht/picklecat/',\n",
       "  '747',\n",
       "  '102',\n",
       "  'dhotson',\n",
       "  '11/29/2015 22:46'],\n",
       " ['11590768',\n",
       "  'Show HN: Shanhu.io, a programming playground powered by e8vm',\n",
       "  'https://shanhu.io',\n",
       "  '1',\n",
       "  '1',\n",
       "  'h8liu',\n",
       "  '4/28/2016 18:05']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show_posts[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11/25/2015 14:03', 26],\n",
       " ['11/29/2015 22:46', 747],\n",
       " ['4/28/2016 18:05', 1],\n",
       " ['7/28/2016 7:11', 3]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import datetime as dt\n",
    "result_list_points_date = []\n",
    "\n",
    "for each in show_posts:\n",
    "    sublist = []\n",
    "    createdtime = each[6]\n",
    "    points = int(each[3])\n",
    "    sublist.append(createdtime)\n",
    "    sublist.append(points)\n",
    "    result_list_points_date.append(sublist)\n",
    "       \n",
    "result_list_points_date[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step helps us focus on the elements required to get the frequency table of **points by hour**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency table creation using the sublist (date, points for each post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21': 866, '03': 679, '22': 1856, '18': 2215, '23': 1526, '12': 2543, '08': 519, '05': 104, '16': 2634, '02': 340, '11': 1480, '15': 2228, '09': 553, '20': 1819, '06': 375, '07': 494, '00': 1173, '04': 386, '14': 2187, '19': 1702, '13': 2438, '01': 700, '17': 2521, '10': 681}\n",
      "{'21': 47, '03': 27, '22': 46, '18': 61, '23': 36, '12': 61, '08': 34, '05': 19, '16': 93, '02': 30, '11': 44, '15': 78, '09': 30, '20': 60, '06': 16, '07': 26, '00': 31, '04': 26, '14': 86, '19': 55, '13': 99, '01': 28, '17': 93, '10': 36}\n"
     ]
    }
   ],
   "source": [
    "show_counts_by_hour = {}\n",
    "points_by_hour = {}\n",
    "\n",
    "for each in result_list_points_date:\n",
    "    dtobj = each[0]\n",
    "    dtparsed = dt.datetime.strptime(dtobj, \"%m/%d/%Y %H:%M\")\n",
    "    hr = dt.datetime.strftime(dtparsed,\"%H\")\n",
    "    #print(hr)\n",
    "    \n",
    "    if hr not in show_counts_by_hour:\n",
    "        show_counts_by_hour[hr] = 1\n",
    "        points_by_hour[hr] = int(each[1])\n",
    "    else:\n",
    "        show_counts_by_hour[hr] = show_counts_by_hour[hr] + 1\n",
    "        points_by_hour[hr] = points_by_hour[hr] + int(each[1])\n",
    "\n",
    "print(points_by_hour)\n",
    "print(show_counts_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average number of points for show post in any hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['21', 18.425531914893618],\n",
       " ['03', 25.14814814814815],\n",
       " ['22', 40.34782608695652],\n",
       " ['18', 36.31147540983606],\n",
       " ['23', 42.388888888888886],\n",
       " ['12', 41.68852459016394],\n",
       " ['08', 15.264705882352942],\n",
       " ['05', 5.473684210526316],\n",
       " ['16', 28.322580645161292],\n",
       " ['02', 11.333333333333334],\n",
       " ['11', 33.63636363636363],\n",
       " ['15', 28.564102564102566],\n",
       " ['09', 18.433333333333334],\n",
       " ['20', 30.316666666666666],\n",
       " ['06', 23.4375],\n",
       " ['07', 19.0],\n",
       " ['00', 37.83870967741935],\n",
       " ['04', 14.846153846153847],\n",
       " ['14', 25.430232558139537],\n",
       " ['19', 30.945454545454545],\n",
       " ['13', 24.626262626262626],\n",
       " ['01', 25.0],\n",
       " ['17', 27.107526881720432],\n",
       " ['10', 18.916666666666668]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_avg_by_hour = []\n",
    "\n",
    "for hour in points_by_hour:\n",
    "    show_avg_by_hour.append([hour,points_by_hour[hour]/show_counts_by_hour[hour]])\n",
    "    \n",
    "show_avg_by_hour    \n",
    "#1. lists can also be created from dictionaries\n",
    "#2. Calculatons can be done on the key values of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting the final list of top hours with more number of points for show posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Swapping the sublist elements of show post 'by hour' categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.425531914893618, '21'], [25.14814814814815, '03'], [40.34782608695652, '22'], [36.31147540983606, '18'], [42.388888888888886, '23'], [41.68852459016394, '12'], [15.264705882352942, '08'], [5.473684210526316, '05'], [28.322580645161292, '16'], [11.333333333333334, '02'], [33.63636363636363, '11'], [28.564102564102566, '15'], [18.433333333333334, '09'], [30.316666666666666, '20'], [23.4375, '06'], [19.0, '07'], [37.83870967741935, '00'], [14.846153846153847, '04'], [25.430232558139537, '14'], [30.945454545454545, '19'], [24.626262626262626, '13'], [25.0, '01'], [27.107526881720432, '17'], [18.916666666666668, '10']]\n"
     ]
    }
   ],
   "source": [
    "swap_showavg_by_hour = []\n",
    "for each in show_avg_by_hour:\n",
    "    #print(key)\n",
    "    #creating a sublist and appending it\n",
    "    sublist = []\n",
    "    sublist.append(each[1])\n",
    "    sublist.append(each[0])\n",
    "    swap_showavg_by_hour.append(sublist)\n",
    "print(swap_showavg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 5 hours for ask posts comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Show Posts Points\n",
      "\n",
      "    23:00: 42.39 average points per post    \n",
      "    \n",
      "\n",
      "    12:00: 41.69 average points per post    \n",
      "    \n",
      "\n",
      "    22:00: 40.35 average points per post    \n",
      "    \n",
      "\n",
      "    00:00: 37.84 average points per post    \n",
      "    \n",
      "\n",
      "    18:00: 36.31 average points per post    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#sorted function to arrange \n",
    "show_sorted_swap = sorted(swap_showavg_by_hour, reverse = True)\n",
    "print(\"Top 5 hours for Show Posts Points\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    hrobj = dt.datetime.strptime(show_sorted_swap[i][1],\"%H\") # Assigns what is what\n",
    "    hrobj_string = dt.datetime.strftime(hrobj, \"%H:%M\") #To final string\n",
    "    show_avg = show_sorted_swap[i][0]\n",
    "    template = '''\n",
    "    {}: {:.2f} average points per post    \n",
    "    '''\n",
    "    print(template.format(hrobj_string,show_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding**: \n",
    "The above times are in EST(eastern standard time). To get more points, I (in IST) can try to create a good number of show posts during **09:30 - 10:30, 22:30 - 23:30, 08:30 - 09:30, 10:30 - 11:30, 04:30 - 05:30** in the same order. Basically, these are the morning work hours for an Indian resident. The top hours which received points on an average are very close in magnitude unlike the comments per hour in the previous analysis on ask posts. This would prompt us to further dig into the data. Location of responders either for comments or for points (upvotes or downvotes) can give us more insight into when to actually schedule a post. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
